#!/usr/bin/env python3

import sys
import subprocess
import json
import logging
from pathlib import Path
from dataclasses import dataclass
from typing import Literal, Optional
import os

@dataclass
class AIConfig:
    provider: Literal["aws-bedrock", "openai"]
    model_id: str
    max_tokens: int
    temperature: float
    user_prompt: str
    system_prompt: str

@dataclass
class AWSConfig:
    profile_name: str

@dataclass
class OpenAIConfig:
    api_key: str

@dataclass
class Config:
    ai: AIConfig
    aws: Optional[AWSConfig] = None
    openai: Optional[OpenAIConfig] = None

def load_and_validate_config(config_file: Path) -> Config:
    try:
        with config_file.open('r') as f:
            config_dict = json.load(f)
    except FileNotFoundError:
        logger.warning(f"Config file not found at {config_file}. Using default values.")
        config_dict = {}

    ai_config = config_dict.get('AI', {})
    ai = AIConfig(
        provider=ai_config.get('provider', 'openai'),
        model_id=ai_config.get('model_id', 'gpt-3.5-turbo'),
        max_tokens=ai_config.get('max_tokens', 300),
        temperature=ai_config.get('temperature', 0.3),
        user_prompt=ai_config.get('user_prompt', DEFAULT_USER_PROMPT),
        system_prompt=ai_config.get('system_prompt', DEFAULT_SYSTEM_PROMPT)
    )

    aws_config = config_dict.get('AWS')
    aws = AWSConfig(profile_name=aws_config['profile_name']) if aws_config else None

    openai_config = config_dict.get('OpenAI')
    openai = OpenAIConfig(api_key=openai_config['api_key']) if openai_config else None

    config = Config(ai=ai, aws=aws, openai=openai)
    validate_config(config)
    return config

def validate_config(config: Config) -> None:
    if config.ai.provider not in {"aws-bedrock", "openai"}:
        raise ValueError(f"Invalid AI provider: {config.ai.provider}")
    
    if config.ai.max_tokens <= 0:
        raise ValueError("max_tokens must be a positive integer")
    
    if not 0 <= config.ai.temperature <= 1:
        raise ValueError("temperature must be between 0 and 1")
    
    if config.ai.provider == "aws-bedrock" and not config.aws:
        raise ValueError("AWS configuration is required when using aws-bedrock provider")
    
    if config.ai.provider == "openai" and not config.openai:
        raise ValueError("OpenAI configuration is required when using openai provider")
    
    if config.ai.provider == "openai" and not (config.openai.api_key or os.environ.get("OPENAI_API_KEY")):
        raise ValueError("OpenAI API key is required. Set it in the config file or as an environment variable.")

def get_git_diff() -> Optional[str]:
    try:
        return subprocess.check_output(['git', 'diff', '--cached'], text=True)
    except subprocess.CalledProcessError as e:
        logger.error(f"Failed to get git diff: {e}")
        return None

def generate_commit_message(diff: str) -> Optional[str]:
    generator = {
        'aws-bedrock': generate_commit_message_bedrock,
        'openai': generate_commit_message_openai
    }.get(config.ai.provider)
    
    if not generator:
        logger.error(f"Unsupported AI provider: {config.ai.provider}")
        return None
    
    return generator(diff)

def generate_commit_message_bedrock(diff: str) -> Optional[str]:
    try:
        import boto3
    except ImportError:
        logger.error("boto3 is required for AWS Bedrock. Install it with 'pip install boto3'")
        return None

    try:
        session = boto3.Session(profile_name=config.aws.profile_name)
        bedrock = session.client('bedrock-runtime')
        
        messages = [
            {"role": "user", "content": config.ai.user_prompt.format(diff=diff)}
        ]
        
        body = json.dumps({
            "anthropic_version": "bedrock-2023-05-31",
            "max_tokens": config.ai.max_tokens,
            "messages": messages,
            "temperature": config.ai.temperature,
            "top_p": 1,
        })
        
        response = bedrock.invoke_model(
            modelId=config.ai.model_id,
            body=body
        )
        
        response_body = json.loads(response['body'].read())
        return response_body['content'][0]['text']
    except Exception as e:
        logger.error(f"Failed to generate commit message with AWS Bedrock: {e}")
        return None

def generate_commit_message_openai(diff: str) -> Optional[str]:
    try:
        import openai
    except ImportError:
        logger.error("openai is required for OpenAI. Install it with 'pip install openai'")
        return None

    try:
        openai.api_key = config.openai.api_key or os.environ.get("OPENAI_API_KEY")
        
        messages = [
            {"role": "system", "content": config.ai.system_prompt},
            {"role": "user", "content": config.ai.user_prompt.format(diff=diff)}
        ]
        
        response = openai.ChatCompletion.create(
            model=config.ai.model_id,
            messages=messages,
            max_tokens=config.ai.max_tokens,
            temperature=config.ai.temperature,
        )
        
        return response.choices[0].message['content'].strip()
    except Exception as e:
        logger.error(f"Failed to generate commit message with OpenAI: {e}")
        return None

def update_commit_message(file_path: str, new_message: str) -> None:
    try:
        with open(file_path, 'r+') as f:
            content = f.read()
            f.seek(0)
            f.write(f"{new_message.strip()}\n\n{content}")
        logger.info("Successfully updated commit message")
    except IOError as e:
        logger.error(f"Failed to update commit message file: {e}")

def main() -> None:
    try:
        commit_msg_file = sys.argv[1]
        diff = get_git_diff()
        if diff:
            commit_message = generate_commit_message(diff)
            if commit_message:
                print(commit_message)
                update_commit_message(commit_msg_file, commit_message)
            else:
                logger.warning("No commit message generated. Using default message.")
        else:
            logger.warning("No diff found. Skipping commit message generation.")
    except Exception as e:
        logger.error(f"An unexpected error occurred: {e}")

if __name__ == '__main__':
    # Load and validate configuration
    config_file = Path.home() / '.git-commit-message-config.json'
    config = load_and_validate_config(config_file)
    
    # Set up logging
    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
    logger = logging.getLogger(__name__)
    
    main()

# Constants
DEFAULT_USER_PROMPT = """Generate a concise and informative commit message based on the following git diff:{diff}"""
DEFAULT_SYSTEM_PROMPT = """You are an AI assistant helping to generate Git commit messages."""